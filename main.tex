\documentclass[final]{beamer}

% beamerposter -----------------------------------------------------------------
%% 36in x 48in = 91.44cm x 121.92
\usepackage[size=custom,width=121.92,height=91.44,scale=1.0]{beamerposter}
\usetheme{gemini}
\usecolortheme{mit}

% Columns ----------------------------------------------------------------------
% % If you have N columns, choose \sepwidth and \colwidth such that
% % (N+1)*\sepwidth + N*\colwidth = \paperwidth
\newlength{\sepwidth}
\newlength{\colwidth}
\newlength{\padwidth}
\setlength{\sepwidth}{ 1.40cm}
\setlength{\colwidth}{28.00cm}
\setlength{\padwidth}{ 2.92cm}

\newcommand{\separatorcolumn}{\begin{column}{\sepwidth}\end{column}}

\setbeamertemplate{footline}[text line]{%
  \begin{beamercolorbox}[colsep*=0ex,center]{block body}
    \vskip2ex
    \normalsize{March 10th, 2023 -- Santa Fe, NM
      \hfill Conference on Data Analysis 2023}
    \vskip2ex
  \end{beamercolorbox}
}%

\setbeamertemplate{bibliography item}{}
\setbeamertemplate{description item}{\textbf{\insertdescriptionitem}}

\title{Automatic Relevance Determination
  for Gaussian Processes with Functional Inputs}

\author{
  \textbf{Luis Damiano}\inst{1},
  Margaret Johnson\inst{2}, Joaquim Teixeira\inst{2},
  Max D. Morris\inst{3},
  Jarad Niemi\inst{1}}

\institute[Iowa State]{
  \inst{1} Department of Statistics, Iowa State University
  \inst{2} Jet Propulsion Laboratory, California Institute of Technology
  \inst{3} Departments of Statistics, and Industrial and Manufacturing
Systems Engineering, Iowa State University}

\usepackage{lipsum}\usepackage[base]{babel} % need to go together
\newcommand{\shortlipsum}{{\color{gray!99} \lipsum[1][1-10]}}

%%
\RequirePackage{tabularray}
\UseTblrLibrary{booktabs}
\UseTblrLibrary{functional} %% Enables evaluate
\NewColumnType{R}{X[r]}
\usepackage{soul}
\setul{.35ex}{.25ex}

%% Math packages
\RequirePackage{amssymb}
\RequirePackage{amsmath}
\RequirePackage{amsthm}
\RequirePackage{mathtools} % provides: coloneqq
\RequirePackage{bm}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\DeclareMathOperator{\evsym}{E}
\newcommand\EE[1]{\evsym\left\langle#1\right\rangle}
\DeclareMathOperator{\vsym}{V}
\newcommand\VV[1]{\vsym\left\langle#1\right\rangle}

%% Citations
%%% Use biblatex
\usepackage[
    backend=bibtex,            % Use legacy bibtex backend (biber is better)
    natbib=true,               % Load aliases for citation commands
    citestyle=numeric-comp,    % Inline: Author year, compressed
    maxcitenames=1,            % Inline: max 1 author name
    bibstyle=authoryear,       % Bibliography: Author year
    giveninits=true,           % Bibliography: first and middle name initials
    dashed=false,              % Bibliography: no dash for recurrent authors
    abbreviate=true,           % Bibliography: abbreviate
    maxbibnames=5,           % Bibliography: max 1 author names
    sorting=nyt,               % Bibliography: sort by name, year, title
    isbn=true,                 % Bibliography: print ISBN
    url=false,                 % Bibliography: don't print URL
    doi=true,                  % Bibliography: print DOI
    eprint=false               % Bibliography: don't print eprint information,
    ]{biblatex}
%%% bibliography: print authors as "last name, first name"
%    \DeclareNameAlias{sortname}{family-given}
%%% Add bib files
    \addbibresource{references.bib}
    \addbibresource{referencesR.bib}
% \csappto{blx@filehook@postload@numeric.bbx}{%
% \mode<presentation>{%
% \setbeamertemplate{bibliography item}{%
% \insertbiblabel}}}
%% \begin{minipage}[position][height][inner-pos]{width}

\begin{document}

\begin{frame}[t]

  \colorbox{pink!0}{
    \begin{minipage}[t][76cm][t]{58cm}
      \colorbox{yellow!0}{
        \begin{minipage}[t][40cm][t]{28cm}
          %Left
          \begin{block}{Automatic Dynamic Relevance Determination}
            A \textbf{framework for Gaussian
            Processes with functional inputs} \citep{damiano2022}.
            We generalize previous work with indexed
            inputs \citep{morris2012,muehlenstaedt2017,kuttubekova2019} and
            incorporate the ideas behind automatic relevance determination
            for vectors \citep{neal1996}.

            Let $X(t)\in\mathcal{X} = \left\{X:[0,1]\to\mathbb{R}\right\}$,
            $t\in[0, 1]$ be a functional input, $y\in\mathbb{R}$ a scalar
            output, and $f:\mathcal{X}\to\mathcal{Y}$ an unknown function with
            evaluations $y_i = f(X_i)$, $i = 1, \dots, N\in\mathbb{N}$. We place
            a GP prior on $f$.
            \begin{align}
              \mathbf{y}
              &\sim \mathcal{N}\left(\mathbf{m}_f, \sigma_{f}^{2} \ \mathbf{R}_f
                + \sigma_{\varepsilon}^{2}\mathbf{I}\right) \\
              {(\mathbf{m}_f)}_i
              &= m_f(X_i) \\
              {\left(\mathbf{R}_f\right)}_{ij}
              &=
                \text{exp}\left\{
                -0.5 \phi^{-2} \ d_f(X_i, X_j)
                \right\}
              \\
              d_f(X_i, X_j)
              &= \int_{\mathcal{T}}
                \omega(t)
                {\left(X_i(t) - X_j(t) \right)}^2 dt
              \\
              \omega(t)
              &: \mathcal{T}\to\mathbb{R}^+
            \end{align}
            Space:
            $\sigma_{\varepsilon}^2 > 0$,
            $\sigma_{f}^2 > 0$,
            $\phi > 0$,
            and $m_f(\cdot)$ is left unspecified w.l.o.g. \\
            Priors:
            $\phi\sim\textsc{InvGamma}$, and
            $\sigma_f, \sigma_\varepsilon \sim \textsc{N}^{+}$
          \end{block}

          \begin{block}{Learning \& validation}
            Fully Bayesian inference on the unknown quantities $\bm{\theta}$.
            One long chain~\citep{raftery1992} with $M \in \mathbb{N}$
            post warm-up samples generated via the NUTS
            algorithm~\citep{hoffman2014},
            \begin{equation}
              \log p(\bm{\theta} | \mathbf{y}, \mathbf{X})
              = -\frac{1}{2}
                 {(\mathbf{y} - \mathbf{m}_y)}^\top
                 {\mathbf{S}_y}^{-1}
                 {(\mathbf{y} - \mathbf{m}_y)}
                 -\frac{1}{2}
                 \log | \mathbf{S}_y |
                 + \log p(\bm{\theta})
               \end{equation}
               where
               ($\mathbf{X}$, $\mathbf{y}$) training input and output,
               ($\mathbf{m}_y $, $\mathbf{S}_y $) mean and covariance.
            % \begin{align}
            %   \label{eq:margina-likelihood}
            %   \log p(\mathbf{y} | \mathbf{X}, \bm{\theta})
            %   =& -\frac{1}{2}
            %      {(\mathbf{y} - \mathbf{m}_y)}^\top
            %      {\mathbf{S}_y}^{-1}
            %      {(\mathbf{y} - \mathbf{m}_y)}
            %      -\frac{1}{2}
            %      \log | \mathbf{S}_y |
            %      - \frac{n}{2} \log 2\pi \\
            %   \label{eq:parameter-posterior}
            %   \log p(\bm{\theta} | \mathbf{y}, \mathbf{X})
            %   \propto&
            %            \log p(\mathbf{y} | \mathbf{X}, \bm{\theta}) +
            %            \log p(\bm{\theta}).
            % \end{align}

            Validation statistic posterior expectation approximated using a thinned
            posterior parameter sample with $\tilde{M} \in \mathbb{N}$ draws,
            \begin{align}
              \hat{v}_1
              &= {\tilde{M}}^{-1} \sum_{{\tilde{m}}=1}^{{\tilde{M}}} N^{-\frac{1}{2}} \norm{%
                \EE{\bm{y}_{*} | \bm{X}, \bm{X}_{*}, \bm{y}, {\bm{\theta}}_{{\tilde{m}}}} -
                \bm{y}_{*}
                } \label{eq:validation-rmse} \\
              \hat{v}_2
              &= {\tilde{M}}^{-1} \sum_{{\tilde{m}}=1}^{{\tilde{M}}}
                p(\bm{y}_{*} | \bm{X}, \bm{X}_{*}, \bm{y},
                {\bm{\theta}}_{{\tilde{m}}}) \label{eq:validation-ppld}
            \end{align}
            where ($\mathbf{X}_\mathbf{*}$, $\mathbf{y}_\mathbf{*}$) test input and output.
          \end{block}
        \end{minipage}
      }
      \colorbox{green!0}{
        \begin{minipage}[t][40cm][t]{28cm}
          % Right
          \begin{block}{Asymmetric Squared Exponential weight function}
            \vskip1ex
            \begin{figure}
              \centering
              \includegraphics[width=.85\linewidth]{inc/coda_weight_profiles_fsc040}
            \end{figure}
            \begin{equation}
              \label{eq:weight-ase}
              \omega(t)
              =
              \begin{cases}
                \text{exp}\left[- {(t - \tau)}^2 \lambda\kappa^{-1}
                \right] & \text{for } t \le \tau \\
                \text{exp}\left[- {(t - \tau)}^2 \lambda\kappa
                \right] & \text{for } t > \tau \\
              \end{cases}
            \end{equation}
            Space:
            $\omega(t): \mathcal{T} = [0, 1] \to (0, 1]$,
            $\tau\in[0,1]$,
            $\lambda > 0$,
            $\kappa > 0$ \\
            Priors:
            $\indent\tau \sim \textsc{Beta}$,
            $\lambda \sim \textsc{N}^{+}$,
            $\log(\kappa) \sim \textsc{N}$
          \end{block}

          \vskip2.9ex
          \begin{block}{Input relevance statistics}
            \begin{minipage}[t]{.45\linewidth}
              \begin{center}
                Most relevant location
              \end{center}
              \begin{equation}
                \tau=\argmax_{t\in\mathcal{T}}\omega(t)
              \end{equation}
            \end{minipage}
            \begin{minipage}[t]{.45\linewidth}
              \begin{center}
                Global relevance
              \end{center}
              \begin{equation}
                \Omega=\phi^{-2}\int_\mathcal{T}\omega(t)\,\mathrm{d}t
              \end{equation}
            \end{minipage}
          \end{block}

          \vskip3ex

          \begin{block}{Choice of weight function}
            \begin{description}
            \item[Dynamic] input predictive relevance varies over the index
              space
            \item[Smoothness] irons out erratic relevance patterns over the
              index space
            \item[Parsimony] fewer parameters than vector representations
            \item[Interpretation] better physical understanding and
              statistical modeling
            \end{description}
          \end{block}
        \end{minipage}
      }
      \vskip3ex
      \colorbox{yellow!0}{
        \begin{minipage}[t][50cm][t]{58cm}
          %Data
          \begin{block}{Microwave Limb Sounder}
            \vskip1ex
            \begin{itemize}
            \item Computer model: forward
              model~\cite{read2006,schwartz2006,waters2006} estimates, or
              \emph{retrieves}, geophysical variables from electromagnetic radiation
            \item Planetwide, daily data products~\cite{liversey2020} and uncertainty
              experiments~\cite{turmon2019,braverman2021} rely on a myriad of runs
            \item Output: score for reflected sunlight around 190GHz~\cite{johnson2020}
            \item Functional input: atmospheric profiles over a vertical grid
            \item We consider some species in pressure regions expected to be
              well-informed by the measurements~\cite{liversey2020}
            \end{itemize}
          \end{block}
          \begin{block}{Data}
            \begin{figure}
              \centering
              \includegraphics[width=.85\linewidth]{inc/mls_input_profiles_fsc045}
            \end{figure}

            \begin{center}
              Radiance score variability seems associated with the tropopause Ozone
              concentration
            \end{center}
          \end{block}
        \end{minipage}
      }
    \end{minipage}%
  }
  \colorbox{blue!0}{
    \begin{minipage}[t][76cm][t]{58cm}
      %Results
      \begin{block}{Are inputs equally relevant over the atmosphere?}
        \vskip1ex
        \begin{figure}
          \centering
          % \includegraphics[width=\textwidth]{inc/mmls_weight_posterior_mini1}
          \includegraphics[width=.85\textwidth]{inc/mls_weight_posterior_fsc060}
          \label{fig:mmls-weight-posterior-mini1}
        \end{figure}
      \end{block}

      \begin{minipage}[t]{58cm}
        \begin{minipage}[t]{28cm}
          \begin{block}{Are all the inputs equally relevant?}
            \vskip1ex
            \begin{figure}
              \centering
              \includegraphics[width=.85\linewidth]{inc/mls_weight_integral_fsc070.pdf}
            \end{figure}
          \end{block}
          \begin{block}{How does ADRD compare to ARD predictionwise?}
            \vskip1ex
            \centering
            \begin{tblr}[evaluate=\fileInput]{
                width=.85\textwidth,
                colspec={Q[l,12ex]RRRRR},
                rows={font=\normalsize, rowsep=5pt}}
              \fileInput{inc/mmls_validation_mean}
            \end{tblr}

            Underline: best in class over 8 data splits using
            $t_{7,.80}\approx1.41$.
          \end{block}

          \begin{block}{In summary}
            \begin{itemize}
            \item ADRD and ARD perform similarly predictionwise
            \item ADRD and ARD agree on the overall relevance patterns
            \item ADRD has $\sim15$ times fewer parameters to learn
            \item ADRD rules out erratic patterns in relevance
            \item ADRD posterior patterns are consistent with the underlying
              science
              \begin{itemize}
              \item Relevance within a chemical species over the vertical grid
                via the $\omega(t)$ function
              \item Relevance between chemical species via the integrated weight
                statistic $\Omega$
              \end{itemize}
            \end{itemize}
          \end{block}
        \end{minipage}
        \begin{minipage}[t]{28cm}
          \begin{block}{Onwards and upwards}
            Toward a framework for Gaussian processes with functional inputs
            $Y = f(X_1(u), X_2(v), \dots, x_1, x_2, \dots)$

            \begin{itemize}
            \item Multiple scalar\textsuperscript{\ddag}, vector, and functional inputs
            \item Flexible functional weight forms: ADE, ASE, FEW\textsuperscript{\ddag}
            \item Case studies: Microwave Limb Sounder,
              Water Erosion Prediction Project\textsuperscript{\ddag}
            \item Exact integral for piecewise linear inputs\textsuperscript{\ddag}
            \end{itemize}

            \textsuperscript{\ddag} Manuscript in preparation
          \end{block}

          \begin{block}{References}
            \vspace{-1ex}
            \renewcommand*{\bibfont}{\small}
            \printbibliography[heading=none]{}
          \end{block}
        \end{minipage}
      \end{minipage}
    \end{minipage}%
  }
  \colorbox{black!0}{
    \begin{minipage}[t][76cm][t]{3cm}
      %Padding
    \end{minipage}%
  }

  \begin{minipage}[t][5cm][t]{116cm}
    \textbf{Acknowledgements}. MLS team at Jet Propulsion
    Laboratory for their insight in the instrument, the forward model, and other
    relevant atmospheric science concepts.
    Partially funded by Iowa State University through the
    Presidential Interdisciplinary Research Initiative on C-CHANGE:~Science
    for a Changing Agriculture, and the Foundation for Food and Agriculture
    Research.
    \textbf{Manuscript}. Modified from
    \href{https://doi.org/10.48550/arXiv.2209.00044}{arXiv:2209.00044}
    % \textbf{Font size}. \the\dimexpr1em % 2.8346456693 mm
    % \textbf{References}.
    % \printbibliography[heading=none]{}
  \end{minipage}




  % \begin{columns}[t]


  %   \separatorcolumn{}







  % \separatorcolumn{}

  % %% Column 1 ------------------------------------------------------------------
  % \begin{column}{\colwidth}
  %   \begin{block}{Automatic Relevance Determination}
  %     $\mathrm{Cor}(y_i, y_j) = e^{-\theta {(x_i - x_j)}^2}$
  %     where $\theta\in\mathbb{R}^+$ is a weight driving the response correlation

  %     \begin{figure}
  %       \centering
  %       \includegraphics{inc/ard_response_profiles.pdf}
  %     \end{figure}
  %   \end{block}

  %   \begin{block}{Automatic Dynamic Relevance Determination}
  %     A framework for Gaussian Processes with functional inputs
  %     $X(t)\in\mathcal{X} = \left\{X:[0,1]\to\mathbb{R}\right\}$, $t\in[0, 1]$
  %     and a scalar output $y\in\mathbb{R}$. Let $f:\mathcal{X}\to\mathcal{Y}$ be
  %     an unknown function with evaluations $y_i = f(X_i)$, $i = 1, \dots,
  %     N\in\mathbb{N}$.
  %     \begin{align}
  %       \mathbf{y}
  %       &\sim \mathcal{N}\left(\mathbf{m}_f, \sigma_{f}^{2} \ \mathbf{R}_f
  %         + \sigma_{\varepsilon}^{2}\mathbf{I}\right) \\
  %       (\mathbf{m}_f)_i
  %       &= m_f(X_i) \\
  %       {\left(\mathbf{R}_f\right)}_{ij}
  %       &=
  %         \text{exp}\left\{
  %         -0.5 \phi^{-2} \ d_f(X_i, X_j)
  %         \right\}
  %       \\
  %       d_f(X_i, X_j)
  %       &= \int_{\mathcal{T}}
  %         \omega(t)
  %         {\left(X_i(t) - X_j(t) \right)}^2 dt
  %       \\
  %       \omega(t)
  %       &: \mathcal{T}\to\mathbb{R}^+
  %     \end{align}
  %     $\sigma_{\varepsilon}^2 > 0$,
  %     $\sigma_{f}^2 > 0$,
  %     $\phi > 0$,
  %     $i, j = 1, \dots, N$,
  %     and $m_f(\cdot)$ is a mean function left unspecified w.l.o.g.
  %   \end{block}

  %   \begin{block}{Choice of weight function}
  %     \begin{itemize}
  %     \item Learn how the input predictive relevance varies over the index
  %       space.
  %     \item Smoothness: Enforce smoothness on relevance over the index space.
  %     \item Parsimony: fewer parameters than the vector representation.
  %     \item Interpretation: for modeling feedback loop and understanding of the
  %       underlying physical model.
  %     \end{itemize}
  %   \end{block}

  %   \begin{block}{Input relevance statistics}
  %     \begin{column}{.4\linewidth}
  %       \begin{equation}
  %         \tau=\argmax_{t\in\mathcal{T}}\omega(t)
  %       \end{equation}
  %     \end{column}
  %     \begin{column}{.4\linewidth}
  %       \begin{equation}
  %         \Omega=\phi^{-2}\int_\mathcal{T}\omega(t)\,\mathrm{d}t
  %       \end{equation}
  %     \end{column}
  %   \end{block}

  %   \begin{block}{Learning \& validation}
  %     Fully Bayesian inference on the unknown quantities $\bm{\theta}$.
  %     One MCMC chain~\citep{raftery1992} with $M \in \mathbb{N}$ post warm-up
  %     samples generated via the NUTS algorithm~\citep{hoffman2014}.
  %     \begin{align}
  %       \label{eq:margina-likelihood}
  %       \log p(\mathbf{y} | \mathbf{X}, \bm{\theta})
  %       =& -\frac{1}{2}
  %          {(\mathbf{y} - \mathbf{m}_y)}^\top
  %          {\mathbf{S}_y}^{-1}
  %          {(\mathbf{y} - \mathbf{m}_y)}
  %          -\frac{1}{2}
  %          \log | \mathbf{S}_y |
  %          - \frac{n}{2} \log 2\pi \\
  %       \label{eq:parameter-posterior}
  %       \log p(\bm{\theta} | \mathbf{y}, \mathbf{X})
  %       \propto&
  %                \log p(\mathbf{y} | \mathbf{X}, \bm{\theta}) +
  %                \log p(\bm{\theta}).
  %     \end{align}

  %     Validation statistic posterior expectation approximated using a thinned
  %     posterior parameter sample with $\tilde{M} \in \mathbb{N}$ draws.
  %     \begin{align}
  %       \hat{v}_1
  %       &= {\tilde{M}}^{-1} \sum_{{\tilde{m}}=1}^{{\tilde{M}}} N^{-\frac{1}{2}} \norm{%
  %         \EE{\bm{y}_{*} | \bm{X}, \bm{X}_{*}, \bm{y}, {\bm{\theta}}_{{\tilde{m}}}} -
  %         \bm{y}_{*}
  %         } \label{eq:validation-rmse} \\
  %       \hat{v}_2
  %       &= {\tilde{M}}^{-1} \sum_{{\tilde{m}}=1}^{{\tilde{M}}}
  %         p(\bm{y}_{*} | \bm{X}, \bm{X}_{*}, \bm{y},
  %         {\bm{\theta}}_{{\tilde{m}}}) \label{eq:validation-ppld}
  %     \end{align}
  %   \end{block}
  % \end{column}

  % \separatorcolumn{}

  % %% Column 2 ------------------------------------------------------------------
  % \begin{column}{\colwidth}
  %   \begin{block}{Microwave Limb Sounder}

  %     \begin{itemize}
  %     \item Computer model: forward
  %       model~\cite{read2006,schwartz2006,waters2006} estimates, or
  %       \emph{retrieves}, geophysical variables from electromagnetic radiation
  %     \item Planetwide, daily data products~\cite{liversey2020} and uncertainty
  %       experiments~\cite{turmon2019,braverman2021} rely on a myriad of runs
  %     \item Output: score for reflected sunlight around 190GHz~\cite{johnson2020}
  %     \item Functional input: atmospheric profiles over a vertical grid
  %     \item We consider some species in pressure regions expected to be
  %       well-informed by the measurements~\cite{liversey2020}
  %     \end{itemize}

  %   \end{block}

  %   \begin{block}{Data}
  %     \begin{figure}
  %       \centering
  %       \includegraphics[width=\linewidth]{inc/mls_input_profiles}
  %     \end{figure}

  %     \begin{center}
  %       Radiance score variability seems associated with the tropopause Ozone
  %       concentration
  %     \end{center}
  %   \end{block}

  %   \begin{block}{Asymmetric Double Exponential weight function}
  %     \begin{figure}
  %       \centering
  %       \includegraphics[width=\linewidth]{inc/mls_weight_profiles}
  %     \end{figure}

  %     \begin{equation}
  %       \omega(t)
  %       =
  %       \text{exp}\left\{-(t - \tau)\lambda\kappa^s s\right\}
  %     \end{equation}
  %     Space:
  %     $\omega(t): \mathcal{T} = [0, 1] \to (0, 1]$,
  %     $s = \text{sign}(t - \tau)$,
  %     $\tau\in[0,1]$,
  %     $\lambda > 0$,
  %     $\kappa > 0$ \\
  %     Priors:
  %     $\indent\tau \sim \textsc{Beta}$,
  %     $\lambda \sim \textsc{N}^{+}$,
  %     $\log(\kappa) \sim \textsc{N}$
  %   \end{block}


  %   \begin{block}{In which part of the atmosphere are the inputs most relevant?}
  %     \begin{figure}
  %       \centering
  %       \includegraphics[width=\textwidth]{inc/mmls_weight_posterior_mini1}
  %       \label{fig:mmls-weight-posterior-mini1}
  %     \end{figure}
  %   \end{block}

  %   \begin{block}{Which inputs are more relevant?}
  %     \begin{figure}
  %       \centering
  %       \includegraphics[width=\linewidth]{inc/mls_weight_integral.pdf}
  %     \end{figure}
  %   \end{block}
  % \end{column}

  % \separatorcolumn{}

  % % Column 3 -------------------------------------------------------------------
  % \begin{column}{\colwidth}
  %   \begin{block}{Water Erosion Prediction Project}
  %     \shortlipsum{}
  %   \end{block}
  % \end{column}

  % \separatorcolumn{}

  % % Column 4 -------------------------------------------------------------------
  % \begin{column}{\colwidth}
  %   \begin{block}{The rest goes here}
  %     \shortlipsum{}
  %   \end{block}
  % \end{column}

  % \separatorcolumn{}

  % % Blank padding to the right -------------------------------------------------
  % \vrule{}
  % \begin{column}{\padwidth}
  %   % padding
  % \end{column}

%\end{columns}
\end{frame}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
